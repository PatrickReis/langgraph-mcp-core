# Configurações do Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3:latest
OLLAMA_EMBEDDINGS_MODEL=nomic-embed-text

# Configurações do ChromaDB
CHROMA_PERSIST_DIRECTORY=./chroma_db

# Configurações de busca vetorial
VECTOR_SEARCH_K_RESULTS=3

# Configurações do servidor MCP
MCP_SERVER_NAME=LangGraphToolsMCP

# Configurações de logging (opcional)
LOG_LEVEL=INFO

# Configurações de Provedores LLM
MAIN_PROVIDER=ollama

# OpenAI Configurações
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Google Gemini Configurações
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-flash
