# LangGraph Agent com MCP Bridge

Este projeto implementa um agente inteligente usando LangGraph com acesso a uma base de conhecimento vetorial e integra√ß√£o MCP (Model Context Protocol).

## üöÄ Configura√ß√£o

### 1. Instalar depend√™ncias
```bash
pip install -r requirements.txt
```

### 2. Configurar vari√°veis de ambiente
Copie o arquivo `.env.example` para `.env` e ajuste as configura√ß√µes:

```bash
cp .env.example .env
```

#### Configura√ß√µes dispon√≠veis:

**Provedor Principal:**
- `MAIN_PROVIDER`: Provedor LLM principal ('ollama', 'openai', 'gemini') (padr√£o: ollama)

**Ollama:**
- `OLLAMA_BASE_URL`: URL do servidor Ollama (padr√£o: http://localhost:11434)
- `OLLAMA_MODEL`: Modelo LLM principal (padr√£o: llama3:latest)
- `OLLAMA_EMBEDDINGS_MODEL`: Modelo para embeddings (padr√£o: nomic-embed-text)

**OpenAI:**
- `OPENAI_API_KEY`: Sua chave de API da OpenAI
- `OPENAI_MODEL`: Modelo OpenAI (padr√£o: gpt-3.5-turbo)

**Google Gemini:**
- `GEMINI_API_KEY`: Sua chave de API do Google AI Studio
- `GEMINI_MODEL`: Modelo Gemini (padr√£o: gemini-1.5-flash)

**ChromaDB:**
- `CHROMA_PERSIST_DIRECTORY`: Diret√≥rio de persist√™ncia (padr√£o: ./chroma_db)

**Busca Vetorial:**
- `VECTOR_SEARCH_K_RESULTS`: N√∫mero de resultados da busca (padr√£o: 3)

**MCP Server:**
- `MCP_SERVER_NAME`: Nome do servidor MCP (padr√£o: LangGraphToolsMCP)

### 3. Configurar Provedor LLM

**Para Ollama (padr√£o):**
```bash
# O arquivo .env j√° est√° configurado para Ollama
ollama serve
```

**Para OpenAI:**
```bash
# Editar .env
MAIN_PROVIDER=openai
OPENAI_API_KEY=sua_chave_aqui

# Instalar depend√™ncia
pip install langchain-openai
```

**Para Google Gemini:**
```bash
# Editar .env
MAIN_PROVIDER=gemini
GEMINI_API_KEY=sua_chave_aqui

# Instalar depend√™ncia
pip install langchain-google-genai
```

### 4. Testar Provedores
```bash
python test_providers.py
```

## üéØ Uso

### Executar o agente principal
```bash
python agent.py
```

### Executar servidor MCP
```bash
fastmcp run mcp_server.py
```

### Executar servidor MCP com HTTP
```bash
fastmcp run mcp_server.py --transport streamable-http --host 127.0.0.1 --port 8088
```

### Testar servidor MCP
```bash
python test_mcp.py
```

### Usar MCP Inspector (Interface Web)
```bash
# Instalar MCP Inspector
pip install mcp-inspector

# Executar (em terminal separado)
mcp-inspector

# Abrir navegador em http://localhost:3000
# Conectar em: http://127.0.0.1:8088/mcp
```

## üîß Funcionalidades

- **Agente Inteligente**: Processa perguntas usando LangGraph
- **Base de Conhecimento**: Busca vetorial com ChromaDB
- **Integra√ß√£o MCP Completa**: Bridge para ferramentas LangChain + Resources + Prompts
- **MCP Resources**: Acesso a configura√ß√µes, status e informa√ß√µes da base de conhecimento
- **MCP Prompts**: Templates predefinidos para diferentes tipos de consultas
- **Orquestra√ß√£o Inteligente**: Decide automaticamente quando usar ferramentas vs resposta direta
- **Configura√ß√£o Flex√≠vel**: Todas as configura√ß√µes via vari√°veis de ambiente
- **M√∫ltiplos Provedores**: Suporte para Ollama, OpenAI e Google Gemini
- **Arquitetura Modular**: Sistema componentizado para f√°cil extens√£o
- **Gera√ß√£o Autom√°tica de Tools**: Converte APIs OpenAPI em ferramentas LangGraph automaticamente

## üìÅ Estrutura do Projeto

```
langgraph/
‚îú‚îÄ‚îÄ agent.py                     # Agente principal com interface de linha de comando
‚îú‚îÄ‚îÄ mcp_server.py               # Servidor MCP completo com Tools, Resources e Prompts
‚îú‚îÄ‚îÄ auto_tools.py               # Script de automa√ß√£o para gera√ß√£o de tools da API
‚îú‚îÄ‚îÄ graphs/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ graph.py                # L√≥gica isolada do LangGraph (grafo, n√≥s, estados)
‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ llm_providers.py        # Sistema modular de provedores LLM
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ tools.py                # Ferramentas de busca vetorial e utilit√°rios
‚îÇ   ‚îî‚îÄ‚îÄ api_tools_auto.py       # Tools geradas automaticamente da API (din√¢mico)
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ openapi_to_tools.py     # Utilit√°rio para convers√£o OpenAPI ‚Üí LangGraph Tools
‚îú‚îÄ‚îÄ openapi/
‚îÇ   ‚îî‚îÄ‚îÄ openapi.json            # Especifica√ß√£o OpenAPI da API
‚îú‚îÄ‚îÄ transform/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ lang_mcp_transform.py   # Bridge entre LangChain e MCP
‚îú‚îÄ‚îÄ logger/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ logger.py               # Sistema de logging colorido
‚îú‚îÄ‚îÄ .env                        # Configura√ß√µes do ambiente (n√£o commitado)
‚îú‚îÄ‚îÄ .env.example               # Exemplo de configura√ß√µes
‚îî‚îÄ‚îÄ requirements.txt           # Depend√™ncias do projeto
```

## üåê Integra√ß√£o MCP

### MCP Tools
- `search_knowledge_base`: Busca na base vetorial ChromaDB
- `get_weather`: Informa√ß√µes meteorol√≥gicas atuais
- `langgraph_orchestrator`: Agente completo com orquestra√ß√£o inteligente

### MCP Resources
- `config://agent`: Configura√ß√£o do agente e ferramentas dispon√≠veis
- `knowledge://base`: Informa√ß√µes sobre a base de conhecimento vetorial
- `status://system`: Status geral do sistema (servidor, agente, tools)

### MCP Prompts
- `agent-query`: Template flex√≠vel para consultas (estilos: conversational, technical, concise, educational)
- `knowledge-search`: Template otimizado para busca na base de conhecimento
- `weather-query`: Template para consultas meteorol√≥gicas
- `tool-orchestration`: Template para tarefas que precisam de m√∫ltiplas ferramentas

### Usando MCP Inspector
1. Execute o servidor MCP: `fastmcp run mcp_server.py --transport streamable-http --host 127.0.0.1 --port 8088`
2. Execute o MCP Inspector: `mcp-inspector`
3. Abra o navegador em `http://localhost:3000`
4. Conecte em: `http://127.0.0.1:8088/mcp`
5. Explore Tools, Resources e Prompts na interface web

## üèóÔ∏è Arquitetura

### Componentes Principais

1. **Agent (agent.py)**
   - Interface de linha de comando
   - Loop interativo para conversa√ß√£o
   - Inicializa√ß√£o e configura√ß√£o do sistema

2. **Graph (graphs/graph.py)**
   - Implementa√ß√£o do grafo LangGraph
   - N√≥s de decis√£o e execu√ß√£o 
   - Estado do agente e fluxo de mensagens
   - Orquestra√ß√£o entre ferramentas e resposta direta

3. **Providers (providers/llm_providers.py)**
   - Sistema modular de provedores LLM
   - Suporte para Ollama, OpenAI, Gemini
   - Configura√ß√£o autom√°tica via vari√°veis de ambiente

4. **Tools (tools/tools.py)**
   - Ferramentas LangChain (busca vetorial, clima)
   - Integra√ß√£o com ChromaDB e APIs externas

5. **Transform (transform/lang_mcp_transform.py)**
   - Bridge entre LangChain e MCP
   - Convers√£o autom√°tica de ferramentas
   - Wrapper ass√≠ncrono para compatibilidade

6. **MCP Server (mcp_server.py)**
   - Servidor MCP completo
   - Exposi√ß√£o de Tools, Resources e Prompts
   - Interface web via MCP Inspector

### Fluxo de Dados

```mermaid
graph TD
    A[Cliente MCP] --> B[MCP Server]
    B --> C[Transform Bridge]
    C --> D[LangGraph Agent]
    D --> E[LLM Provider]
    D --> F[Tools]
    F --> G[ChromaDB]
    F --> H[Weather API]
    
    B --> I[Resources]
    B --> J[Prompts]
    
    I --> K[Config]
    I --> L[Status] 
    I --> M[Knowledge Base Info]
```

### Decis√£o de Orquestra√ß√£o

O agente decide automaticamente entre:

1. **Resposta Direta**: Para conversas gerais
2. **Busca na Base**: Para t√≥picos t√©cnicos (python, IA, etc.)
3. **Ferramentas Externas**: Para clima, c√°lculos espec√≠ficos
4. **Combina√ß√£o**: Usar m√∫ltiplas ferramentas quando necess√°rio

## üõ†Ô∏è Gera√ß√£o Autom√°tica de Tools

### Vis√£o Geral

O sistema permite converter automaticamente especifica√ß√µes OpenAPI/Swagger em ferramentas LangGraph funcionais, eliminando a necessidade de criar tools manualmente para cada endpoint da API.

### Arquivos Principais

- **`auto_tools.py`**: Script de automa√ß√£o completa que orquestra todo o processo
- **`utils/openapi_to_tools.py`**: Utilit√°rio base para convers√£o OpenAPI ‚Üí LangGraph Tools
- **`openapi/openapi.json`**: Especifica√ß√£o OpenAPI da sua API
- **`tools/api_tools_auto.py`**: Arquivo gerado dinamicamente com as tools

### Como Usar

#### 1. Preparar OpenAPI
Coloque sua especifica√ß√£o OpenAPI no arquivo `openapi/openapi.json`:

```json
{
  "openapi": "3.1.0",
  "info": {
    "title": "Minha API",
    "version": "1.0.0"
  },
  "paths": {
    "/users": {
      "get": {
        "summary": "List Users",
        "operationId": "list_users"
      }
    }
  }
}
```

#### 2. Gerar Tools Automaticamente
Execute o script de automa√ß√£o:

```bash
python auto_tools.py
```

#### 3. Resultado
O script ir√°:
- ‚úÖ Ler `openapi/openapi.json`
- ‚úÖ Gerar `tools/api_tools_auto.py` com todas as ferramentas
- ‚úÖ Atualizar automaticamente `tools/tools.py` para incluir as novas tools
- ‚úÖ Integrar as ferramentas no agente sem necessidade de restart

### Exemplo de Output

Para uma API CRUD simples, o sistema gera automaticamente:

```python
@tool
def list_users() -> Dict[str, Any]:
    """List Users"""
    url = f"{BASE_URL}/users"
    try:
        response = requests.get(url)
        response.raise_for_status()
        return {"status": "success", "data": response.json()}
    except requests.exceptions.RequestException as e:
        return {"status": "error", "message": str(e)}

@tool  
def create_user(name: str, email: str) -> Dict[str, Any]:
    """Create User"""
    url = f"{BASE_URL}/users"
    try:
        json_data = {"name": name, "email": email}
        response = requests.post(url, json=json_data)
        response.raise_for_status()
        return {"status": "success", "data": response.json()}
    except requests.exceptions.RequestException as e:
        return {"status": "error", "message": str(e)}
```

### Funcionalidades Suportadas

- **M√©todos HTTP**: GET, POST, PUT, DELETE, PATCH
- **Par√¢metros**: Path, Query, Request Body
- **Tipos de Dados**: string, integer, boolean, object, array
- **Valida√ß√£o**: Par√¢metros obrigat√≥rios vs opcionais
- **Documenta√ß√£o**: Gera√ß√£o autom√°tica de docstrings
- **Tratamento de Erros**: Captura e formata√ß√£o de exce√ß√µes HTTP

### Configura√ß√£o Personalizada

#### Alterar URL Base da API
Edite `auto_tools.py`:

```python
base_url = "https://minha-api.com/api/v1"  # Altere aqui
```

#### Personalizar Nome do Arquivo de Sa√≠da
```python
output_file = "tools/minhas_tools_customizadas.py"  # Altere aqui
```

### Workflow para Desenvolvedores

1. **Desenvolvimento da API**: Crie sua API com documenta√ß√£o OpenAPI
2. **Exportar OpenAPI**: Salve o JSON em `openapi/openapi.json`
3. **Executar Script**: `python auto_tools.py`
4. **Testar**: As tools est√£o automaticamente dispon√≠veis no agente
5. **Iterar**: Atualize a API, execute o script novamente

### Integra√ß√£o com CI/CD

```bash
# No seu pipeline de deploy
python auto_tools.py  # Regenera tools automaticamente
python agent.py --test  # Testa o agente com as novas tools
```

### Vantagens

- **Velocidade**: Gera dezenas de tools em segundos
- **Consist√™ncia**: Todas as tools seguem o mesmo padr√£o
- **Manutenibilidade**: Altera√ß√µes na API s√£o refletidas automaticamente
- **Documenta√ß√£o**: Tools auto-documentadas com base no OpenAPI
- **Tipagem**: Par√¢metros e retornos tipados corretamente